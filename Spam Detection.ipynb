{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1928,
     "status": "ok",
     "timestamp": 1678653763490,
     "user": {
      "displayName": "Satyanarayana Vinay Achanta",
      "userId": "14802231585218067533"
     },
     "user_tz": 360
    },
    "id": "888aH_ofmgsv",
    "outputId": "c98a9f62-4b0a-4e22-a153-c17fb7e25ac0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1678653763491,
     "user": {
      "displayName": "Satyanarayana Vinay Achanta",
      "userId": "14802231585218067533"
     },
     "user_tz": 360
    },
    "id": "gm-D48Q3mgwu",
    "outputId": "4a2cca4d-c503-443d-a1b3-f1af0ac75e57"
   },
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label', 'text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for Ham and Spam Count\n",
    "plot_data = df.groupby('label')['text'].nunique()\n",
    "colors = ['#FF0000', '#90EE90']\n",
    "plot_data.plot(kind='bar', color=colors, figsize=(4,3))\n",
    "plt.title('Count of Ham of Spam')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Unique Texts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spam Words WordCloud\n",
    "spam_text = \" \".join(df[df['label'] == 'spam']['text'])\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(spam_text)\n",
    "plt.figure(figsize=(5, 5), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.title('WordCloud of Top Spam Words')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig('2.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1678653763491,
     "user": {
      "displayName": "Satyanarayana Vinay Achanta",
      "userId": "14802231585218067533"
     },
     "user_tz": 360
    },
    "id": "mTr2D8ihimT-",
    "outputId": "56ce5de9-3100-48f6-9e0c-de35689b29f5"
   },
   "outputs": [],
   "source": [
    "#Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1678653763491,
     "user": {
      "displayName": "Satyanarayana Vinay Achanta",
      "userId": "14802231585218067533"
     },
     "user_tz": 360
    },
    "id": "k-FNlTYSmgzX"
   },
   "outputs": [],
   "source": [
    "#Preprocessing Text from Dataset\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)   \n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words] \n",
    "    return ' '.join(words)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 3167,
     "status": "ok",
     "timestamp": 1678653766650,
     "user": {
      "displayName": "Satyanarayana Vinay Achanta",
      "userId": "14802231585218067533"
     },
     "user_tz": 360
    },
    "id": "t6Lqj3xdmg1_",
    "outputId": "b6a84c21-5e82-4c84-89ee-a05385dd6f3f"
   },
   "outputs": [],
   "source": [
    "#Applying Preprocessing to Data\n",
    "df['text'] = df['text'].apply(preprocess_text) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1678653766803,
     "user": {
      "displayName": "Satyanarayana Vinay Achanta",
      "userId": "14802231585218067533"
     },
     "user_tz": 360
    },
    "id": "doPI1vY0mg4u"
   },
   "outputs": [],
   "source": [
    "#Function for using Count Vecorizer with Multinomial Naive Bayes\n",
    "def count_vectorizer_with_MNB():\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df['text'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.2, random_state=42)\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('MultinomialNB using CountVectorizer:')\n",
    "    print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "    print('Precision Score:', precision_score(y_test, y_pred, pos_label='spam'))\n",
    "    print('Recall Score:', recall_score(y_test, y_pred, pos_label='spam'))\n",
    "    print('F1 Score:', f1_score(y_test, y_pred, pos_label='spam'))\n",
    "    print('Confusion Matrix:', confusion_matrix(y_test, y_pred))\n",
    "    print('Cross-validation Scores:', cross_val_score(clf, X, df['label'], cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for using TfidfVectorizer with Multinomial Naive Bayes\n",
    "def tfidf_vectorizer_with_MNB():\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(df['text'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.2, random_state=42)\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('MultinomialNB using TfidfVectorizer:')\n",
    "    print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "    print('Precision Score:', precision_score(y_test, y_pred, pos_label='spam'))\n",
    "    print('Recall Score:', recall_score(y_test, y_pred, pos_label='spam'))\n",
    "    print('F1 Score:', f1_score(y_test, y_pred, pos_label='spam'))\n",
    "    print('Confusion Matrix:', confusion_matrix(y_test, y_pred))\n",
    "    print('Cross-validation Scores:', cross_val_score(clf, X, df['label'], cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result Using CountVecorizer with Multinomial Naive Bayes\n",
    "count_vectorizer_with_MNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result Using TfidfVectorizer with Multinomial Naive Bayes\n",
    "tfidf_vectorizer_with_MNB()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNiQxQfOuXxMfZjEgaD6Cef",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
